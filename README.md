# Snowflake + Tensorlake Integration Examples

<p align="center">
  <img src="https://img.shields.io/badge/Snowflake-29B5E8?style=for-the-badge&logo=snowflake&logoColor=white" />
  <img src="https://img.shields.io/badge/Tensorlake-00A86B?style=for-the-badge&logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAABCGlDQ1BJQ0MgUHJvZmlsZQAAeJxjYGA8wQAELAYMDLl5JUVB7k4KEZFRCuwPGBiBEAwSk4sLGHADoKpv1yBqL+viUYcLcKakFicD6Q9ArFIEtBxopAiQLZIOYWuA2EkQtg2IXV5SUAJkB4DYRSFBzkB2CpCtkY7ETkJiJxcUgdT3ANk2uTmlyQh3M/Ck5oUGA2kOIJZhKGYIYnBncAL5H6IkfxEDg8VXBgbmCQixpJkMDNtbGRgkbiHEVBYwMPC3MDBsO48QQ4RJQWJRIliIBYiZ0tIYGD4tZ2DgjWRgEL7AwMAVDQsIHG5TALvNnSEfCNMZchhSgSKeDHkMyQx6QJYRgwGDIYMZAKbWPz9HbOBQAAAD20lEQVR42pWUb0zVZRTHv+c8v9+9V8CBIkzGDEOoBMw5NrfeeLWlsuWquV22XPXGTafp2krbkuWPuzSyrbZqOKj1zpFCazVcU2gDtnrVaIWKQyFlE0kEAsnLvfx+zzm94LL4Z6vvm+fZOd/n8/w5zw6wvBgxGDxKszleLkXLmltgAQDPFWcjkiwLpagQAISdocCaXvzw++QS77LAOcOO9UUUtscJulcZBZR2qRAADEPpu9B06kyq697txVBaDDNVhTEl06BGVwM665DZQVkBZQAEDnRc1R6Sy3eb50NngR4YcQjvXlctLl0gawFmwMp1JXzDVq8YAMJUIYS9xFQmQiAm0EzwsrTfPT/HoPREUbWumJV6lG1EWZmseU8RPo1L/amFz1IWogeTNTDmJNQKqSbF5c1ovTMAD2SQD0YvhB5f+RlCXAkCwWotLg3Von9cEIWDrSCUg5EHg+/vBxiY6uDiTIHhZ2HYJZ/yMfDga+SDCQCyqtbmPRTnBkKUCV+v6eU7WxCFgy5YALrkZ0Rh0IWAdhf8AsepQICEyswTaL834gDAtJhtyDA5IILxg6YgvdLzPEJtp+lFvgJAWecIoXO7xDvjabKeg8sfqWuyTZKiFmhxAMAkwz1Oht0vKSuOj/ZAQdHOKOI74oI4ZOEBuxDtiHLX9i4K73TPB9MY5zCz+uY3O1dlJoLo7M2IgPQUh7v3FUmerQ5N8yYrQsa1V1JTprlxy4Xbi71zDAKAo9defZENb/3xq7HT3fGLCa/Dc+4X9e93iU5l5EbWUMgAorB+gMRYctwIaoY2vPRFC1XbysbKjG3RjTVi8fMn5ee+JQA4duO1DW7Wiv4g4V8ncW5ayHonh54OhV0kR1JXZ9i/yAIo057M3EiFpgT+pO2BYlAcLolk8kY7ZUs/KP2yn2LNMdNS3WLfuXmgNbdk1Z4gqRARJP5MJKzV+rqihrf/KTThxOChM2zoSGZOJIMM4EZcjN6aaK0rbnjBU49JFUQE9YbeXBMy7i71bb5DPOmK0/bWY+8PHel7ZfMMpTZBBA6Fr559sunXU30nCpFpd1q1OStcM8ITftuxpz4eVVWiR3Wow937isKr3c8tgl2hVQ4UwMyED1JuCxJy4Gx50+C/ti9PPR7GsCnoy8qeDj88SSxHI7kh/PVHEgLtBlk1MJVZazMoOZoCBPUr/Uh8sDQ1UYACG6e4LGlfqkoHuw862bnm+YjDx0UQFp/eqCup/wlQvHvr9WdIzadsEMxI6sPRMb3YWNkYEJHiv8jzdLYrKwjpL+Z5HuP/KtYcM3OAWHPMLIinN5gfn6+/Adz6xlBFC8DNAAAAAElFTkSuQmCC&logoColor=white" />
  <img src="https://img.shields.io/badge/Python-3.9+-3776AB?style=for-the-badge&logo=python&logoColor=white" />
  <img src="https://img.shields.io/badge/Document_AI-4ECDC4?style=for-the-badge&logo=artificial-intelligence&logoColor=white" />
  <img src="https://img.shields.io/badge/Serverless-FFA116?style=for-the-badge&logo=aws-lambda&logoColor=white" />
  <img src="https://img.shields.io/badge/RAG-8B5CF6?style=for-the-badge&logo=openai&logoColor=white" />
</p>
<p align="center">
  <a href="https://docs.tensorlake.ai"><img src="https://img.shields.io/badge/docs-tensorlake.ai-blue?style=flat-square" /></a>
  <a href="https://pypi.org/project/tensorlake/"><img src="https://img.shields.io/pypi/v/tensorlake?style=flat-square&label=tensorlake" /></a>
  <a href="https://tlake.link/slack"><img src="https://img.shields.io/badge/slack-join_community-611f69.svg?style=flat-square&logo=slack" /></a>
  <img src="https://img.shields.io/badge/license-MIT-green?style=flat-square" />
</p>

## Transform Unstructured Data into Queryable and AI Ready Data on Snowflake

Tensorlake is a serverless platform for building data applications and agents in Python that can ingest and transform unstructured data before landing them in Snowflake's SQL database or Cortex Search Engine. This is an alternative to perform ETL orchestration with SQL expressions and UDF functions. 

Tensorlake's applications automatically behave like durable queues so you wouldn't need to setup Kafka or other queues to manage ingestion. The clusters automatically scales up as data is ingested to process them.

### Use Cases

We present some blueprints for production ready patterns to integrate with Snowflake and code that you can deploy under 2 minutes and expereince the integration.

### Blueprint: Document Ingestion Pipeline

<img width="1576" height="552" alt="image" src="https://github.com/user-attachments/assets/128ec329-8bf8-4b64-b6d7-85462c2a9295" />

The Tensoralake application receives Document URLs over HTTP, uses an OCR API to parse the document, calls an LLM for structured extraction, and then uses Snowflake's JDBC driver to write structured data into your Snowflake Database. Once it's inside Snowflake you can do all sorts of analytics on the data. 

The application is written in Python, without any external orchestration engines, so you can build and test it like any other normal application. You can use any OCR API in the application, or even run open source OCR models on GPUs by annotating the OCR function with a GPU enabled hardware resource. 

Tensorlake automatically queues requests and scales out the cluster, there is no extra configuration required for handling spiky ingestion.

[Code](https://github.com/tensorlakeai/snowflake/tree/main/sec-filings)


### Blueprint: Structured Data Extraction

### Blueprint: Document Indexing with Cortex

### Table of Contents
- [Quick Start](#quick-start-tensorlake-applications---serverless-ai-apps-in-minutes)
- [Why this integration matters](#why-this-integration-matters)
- [Key Technical Advantages](#key-technical-advantages)
- [Security and Compliance](#security--compliance)
- [Documentation and Resource](#documentation--resources)
- [Support](#support)

## Quick Start: Tensorlake Applications - Serverless AI Apps in Minutes

**Build and deploy production AI applications that process documents at scale, no infrastructure required.** Tensorlake Applications provide a complete serverless platform for creating data-centric AI apps that integrate seamlessly with Snowflake.

### Prerequisites

- Snowflake account
- Tensorlake API key ([get one here](https://cloud.tensorlake.ai))
- Python 3.9+

### Installation

```bash
# Clone the repository
git clone https://github.com/tensorlakeai/snowflake
cd specific-example # e.g. sec-filings

# Install dependencies
pip install tensorlake snowflake-connector-python pandas numpy

# Set Tensorlake Secrets for deployed Applications
tensorlake secrets set TENSORLAKE_API_KEY="YOUR_TENSORLAKE_API_KEY"
tensorlake secrets set SNOWFLAKE_ACCOUNT='YOUR_SNOWFLAKE_ACCOUNT'
tensorlake secrets set SNOWFLAKE_USER='YOUR_SNOWFLAKE_USER'
tensorlake secrets set SNOWFLAKE_PASSWORD='YOUR_SNOWFLAKE_PASSWORD'
tensorlake secrets set SNOWFLAKE_WAREHOUSE='YOUR_SNOWFLAKE_WAREHOUSE'
tensorlake secrets set SNOWFLAKE_DATABASE='YOUR_SNOWFLAKE_DATABASE'
tensorlake secrets set SNOWFLAKE_SCHEMA='YOUR_SNOWFLAKE_SCHEMA'
```

### Example Application
*Note: This is psuedo code. To try out a fully functional example, explore [sec-filings](./sec-filings).*

```python
# Define the image for the application
image = (
    Image(base_image="python:3.11-slim", name="snowflake-sec")
    .run("pip install snowflake-connector-python pandas pyarrow")
)

# Specify the entry point to the application
# Specify any secrets needed for this funciton
# Specify the image needed for this funciton
@application()
@function(
    secrets=[
        "TENSORLAKE_API_KEY",
        "SNOWFLAKE_ACCOUNT",
        "SNOWFLAKE_USER", 
        "SNOWFLAKE_PASSWORD",
        "SNOWFLAKE_WAREHOUSE"
    ], 
    image=image
)
def document_ingestion(document_url:str) -> None:
    """Main entry point for document processing pipeline"""
    doc_ai = DocumentAI(api_key=os.getenv("TENSORLAKE_API_KEY"))

    # Classify pages that reference AI risks
    parse_id = doc_ai.classify(file_url, page_classifications)

    return extract_structured_data((file_url, parse_id))

@function(
    image=image, 
    secrets=[
        "TENSORLAKE_API_KEY",
        "SNOWFLAKE_ACCOUNT",
        "SNOWFLAKE_USER",
        "SNOWFLAKE_PASSWORD",
        "SNOWFLAKE_WAREHOUSE"
    ]
)
def extract_structured_data(url_page_numbers_pair: Tuple[str, str]) -> None:
    """Extract structured data from classified pages"""
    doc_ai = DocumentAI(api_key=os.getenv("TENSORLAKE_API_KEY"))
    page_classes = doc_ai.wait_for_completion(parse_id=url_page_numbers_pair[1]).page_classes

    # Extract AI risk mentions only from pages that mention AI risks
    result = doc_ai.extract(
        file_url=url_page_numbers_pair[0],
        page_range=page_classes,
        structured_extraction_options=[
            StructuredExtractionOptions(
                schema_name="AIRiskExtraction", 
                json_schema=AIRiskExtraction 
            )
        ]
    )
    
    return write_to_snowflake(result, url_parse_id_pair[0])

@function(
    image=image, 
    secrets=[
        "TENSORLAKE_API_KEY",
        "SNOWFLAKE_ACCOUNT",
        "SNOWFLAKE_USER",
        "SNOWFLAKE_PASSWORD",
        "SNOWFLAKE_WAREHOUSE",
        "SNOWFLAKE_DATABASE",
        "SNOWFLAKE_SCHEMA"
    ]
)
def write_to_snowflake(parse_id: str, file_url: str) -> None:
    """Write extracted data to Snowflake"""
    import pandas as pd

    # Get the extracted data from Tensorlake
    doc_ai = DocumentAI(api_key=os.getenv("TENSORLAKE_API_KEY"))
    result: ParseResult = doc_ai.get_parsed_results(parse_id)

    # Connect to Snowflake
    conn = snowflake.connector.connect(
                account=os.getenv("SNOWFLAKE_ACCOUNT"),
                user=os.getenv("SNOWFLAKE_USER"),
                password=os.getenv("SNOWFLAKE_PASSWORD"),
                warehouse=os.getenv("SNOWFLAKE_WAREHOUSE")
    )
    cursor = conn.cursor()

    # Write data to Snowflake
    try:
        cursor.execute(f"USE DATABASE {os.getenv('SNOWFLAKE_DATABASE')}")
        cursor.execute(f"USE SCHEMA {os.getenv('SNOWFLAKE_SCHEMA')}")
        
        # Write parent table
        write_pandas(conn, df_parent, 'AI_RISK_FILINGS')
        
    finally:
        cursor.close()
        conn.close()
```

- Deploy with one command: `tensorlake deploy process-sec.py`
- Instantly hit the HTTP endpoint: `https://api.tensorlake.ai/applications/document-ingestion`

## Why This Integration Matters

While Snowflake excels at structured data and offers powerful AI through Cortex, **enterprise knowledge remains trapped in complex documents**. Tensorlake bridges this gap with:

- **Serverless AI Applications** that deploy instantly and scale automatically
- **Layout-aware document understanding** preserving tables and semantic structure
- **Dynamic model orchestration** adapting to document complexity in real-time

## Key Technical Advantages

### Tensorlake Applications - Serverless Document AI Platform
Build and deploy AI applications that process documents at scale without managing infrastructure:

- **Instant deployment**: From code to production in seconds
- **Auto-scaling**: Handles 0 to millions of documents automatically  
- **Built-in orchestration**: Parallel processing, retries, monitoring included
- **Easy Snowflake integration**: Read/write data without complex ETL
- **Pay-per-use**: No idle costs, scales to zero when not in use

### Tensorlake's Document Intelligence
- **99.5% extraction accuracy** on complex financial documents, ACORD forms, and regulatory filings
- **Adaptive processing pipeline** switches between OCR, table recognition, and layout models dynamically
- **Preserves document semantics**: headers, tables, footnotes, strikethroughs remain contextually linked
- **Handles 50+ languages** with boundary-preserving multilingual NLP

### Snowflake's AI Infrastructure
- **Native VECTOR data type** with hardware-optimized similarity search
- **Cortex Search**: Hybrid keyword + vector search with automatic reranking
- **Cortex LLM Functions**: Direct SQL access to state-of-the-art models
- **Zero-ETL architecture**: Process documents where your data lives
- **Enterprise governance**: Row-level security, data lineage, and compliance built-in

## Security & Compliance

- **SOC 2 Type II** certified infrastructure
- **HIPAA/GDPR** compliant processing
- **Row-level security** in Snowflake
- **Audit logging** for all operations

## Documentation & Resources

- [Full API Documentation](https://docs.tensorlake.ai)
- [Snowflake Docs](https://docs.snowflake.com)

## Support

- **Tensorlake Slack**: [Join our community](https://tlake.link/slack)
- **GitHub Issues**: [Report bugs or request features](https://github.com/tensorlakeai/snowflake/issues)
- **Enterprise Support**: support@tensorlake.ai

---

<p align="center">
  <img src="https://img.shields.io/badge/Powered_by-Tensorlake-00A86B?style=flat-square&logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAABCGlDQ1BJQ0MgUHJvZmlsZQAAeJxjYGA8wQAELAYMDLl5JUVB7k4KEZFRCuwPGBiBEAwSk4sLGHADoKpv1yBqL+viUYcLcKakFicD6Q9ArFIEtBxopAiQLZIOYWuA2EkQtg2IXV5SUAJkB4DYRSFBzkB2CpCtkY7ETkJiJxcUgdT3ANk2uTmlyQh3M/Ck5oUGA2kOIJZhKGYIYnBncAL5H6IkfxEDg8VXBgbmCQixpJkMDNtbGRgkbiHEVBYwMPC3MDBsO48QQ4RJQWJRIliIBYiZ0tIYGD4tZ2DgjWRgEL7AwMAVDQsIHG5TALvNnSEfCNMZchhSgSKeDHkMyQx6QJYRgwGDIYMZAKbWPz9HbOBQAAAD20lEQVR42pWUb0zVZRTHv+c8v9+9V8CBIkzGDEOoBMw5NrfeeLWlsuWquV22XPXGTafp2krbkuWPuzSyrbZqOKj1zpFCazVcU2gDtnrVaIWKQyFlE0kEAsnLvfx+zzm94LL4Z6vvm+fZOd/n8/w5zw6wvBgxGDxKszleLkXLmltgAQDPFWcjkiwLpagQAISdocCaXvzw++QS77LAOcOO9UUUtscJulcZBZR2qRAADEPpu9B06kyq697txVBaDDNVhTEl06BGVwM665DZQVkBZQAEDnRc1R6Sy3eb50NngR4YcQjvXlctLl0gawFmwMp1JXzDVq8YAMJUIYS9xFQmQiAm0EzwsrTfPT/HoPREUbWumJV6lG1EWZmseU8RPo1L/amFz1IWogeTNTDmJNQKqSbF5c1ovTMAD2SQD0YvhB5f+RlCXAkCwWotLg3Von9cEIWDrSCUg5EHg+/vBxiY6uDiTIHhZ2HYJZ/yMfDga+SDCQCyqtbmPRTnBkKUCV+v6eU7WxCFgy5YALrkZ0Rh0IWAdhf8AsepQICEyswTaL834gDAtJhtyDA5IILxg6YgvdLzPEJtp+lFvgJAWecIoXO7xDvjabKeg8sfqWuyTZKiFmhxAMAkwz1Oht0vKSuOj/ZAQdHOKOI74oI4ZOEBuxDtiHLX9i4K73TPB9MY5zCz+uY3O1dlJoLo7M2IgPQUh7v3FUmerQ5N8yYrQsa1V1JTprlxy4Xbi71zDAKAo9defZENb/3xq7HT3fGLCa/Dc+4X9e93iU5l5EbWUMgAorB+gMRYctwIaoY2vPRFC1XbysbKjG3RjTVi8fMn5ee+JQA4duO1DW7Wiv4g4V8ncW5ayHonh54OhV0kR1JXZ9i/yAIo057M3EiFpgT+pO2BYlAcLolk8kY7ZUs/KP2yn2LNMdNS3WLfuXmgNbdk1Z4gqRARJP5MJKzV+rqihrf/KTThxOChM2zoSGZOJIMM4EZcjN6aaK0rbnjBU49JFUQE9YbeXBMy7i71bb5DPOmK0/bWY+8PHel7ZfMMpTZBBA6Fr559sunXU30nCpFpd1q1OStcM8ITftuxpz4eVVWiR3Wow937isKr3c8tgl2hVQ4UwMyED1JuCxJy4Gx50+C/ti9PPR7GsCnoy8qeDj88SSxHI7kh/PVHEgLtBlk1MJVZazMoOZoCBPUr/Uh8sDQ1UYACG6e4LGlfqkoHuw862bnm+YjDx0UQFp/eqCup/wlQvHvr9WdIzadsEMxI6sPRMb3YWNkYEJHiv8jzdLYrKwjpL+Z5HuP/KtYcM3OAWHPMLIinN5gfn6+/Adz6xlBFC8DNAAAAAElFTkSuQmCC)" />
</p>
