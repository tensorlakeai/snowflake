# Snowflake + Tensorlake Integration Examples

<p align="center">
  <img src="https://img.shields.io/badge/Snowflake-29B5E8?style=for-the-badge&logo=snowflake&logoColor=white" />
  <img src="https://img.shields.io/badge/Tensorlake-00A86B?style=for-the-badge&logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAABCGlDQ1BJQ0MgUHJvZmlsZQAAeJxjYGA8wQAELAYMDLl5JUVB7k4KEZFRCuwPGBiBEAwSk4sLGHADoKpv1yBqL+viUYcLcKakFicD6Q9ArFIEtBxopAiQLZIOYWuA2EkQtg2IXV5SUAJkB4DYRSFBzkB2CpCtkY7ETkJiJxcUgdT3ANk2uTmlyQh3M/Ck5oUGA2kOIJZhKGYIYnBncAL5H6IkfxEDg8VXBgbmCQixpJkMDNtbGRgkbiHEVBYwMPC3MDBsO48QQ4RJQWJRIliIBYiZ0tIYGD4tZ2DgjWRgEL7AwMAVDQsIHG5TALvNnSEfCNMZchhSgSKeDHkMyQx6QJYRgwGDIYMZAKbWPz9HbOBQAAAD20lEQVR42pWUb0zVZRTHv+c8v9+9V8CBIkzGDEOoBMw5NrfeeLWlsuWquV22XPXGTafp2krbkuWPuzSyrbZqOKj1zpFCazVcU2gDtnrVaIWKQyFlE0kEAsnLvfx+zzm94LL4Z6vvm+fZOd/n8/w5zw6wvBgxGDxKszleLkXLmltgAQDPFWcjkiwLpagQAISdocCaXvzw++QS77LAOcOO9UUUtscJulcZBZR2qRAADEPpu9B06kyq697txVBaDDNVhTEl06BGVwM665DZQVkBZQAEDnRc1R6Sy3eb50NngR4YcQjvXlctLl0gawFmwMp1JXzDVq8YAMJUIYS9xFQmQiAm0EzwsrTfPT/HoPREUbWumJV6lG1EWZmseU8RPo1L/amFz1IWogeTNTDmJNQKqSbF5c1ovTMAD2SQD0YvhB5f+RlCXAkCwWotLg3Von9cEIWDrSCUg5EHg+/vBxiY6uDiTIHhZ2HYJZ/yMfDga+SDCQCyqtbmPRTnBkKUCV+v6eU7WxCFgy5YALrkZ0Rh0IWAdhf8AsepQICEyswTaL834gDAtJhtyDA5IILxg6YgvdLzPEJtp+lFvgJAWecIoXO7xDvjabKeg8sfqWuyTZKiFmhxAMAkwz1Oht0vKSuOj/ZAQdHOKOI74oI4ZOEBuxDtiHLX9i4K73TPB9MY5zCz+uY3O1dlJoLo7M2IgPQUh7v3FUmerQ5N8yYrQsa1V1JTprlxy4Xbi71zDAKAo9defZENb/3xq7HT3fGLCa/Dc+4X9e93iU5l5EbWUMgAorB+gMRYctwIaoY2vPRFC1XbysbKjG3RjTVi8fMn5ee+JQA4duO1DW7Wiv4g4V8ncW5ayHonh54OhV0kR1JXZ9i/yAIo057M3EiFpgT+pO2BYlAcLolk8kY7ZUs/KP2yn2LNMdNS3WLfuXmgNbdk1Z4gqRARJP5MJKzV+rqihrf/KTThxOChM2zoSGZOJIMM4EZcjN6aaK0rbnjBU49JFUQE9YbeXBMy7i71bb5DPOmK0/bWY+8PHel7ZfMMpTZBBA6Fr559sunXU30nCpFpd1q1OStcM8ITftuxpz4eVVWiR3Wow937isKr3c8tgl2hVQ4UwMyED1JuCxJy4Gx50+C/ti9PPR7GsCnoy8qeDj88SSxHI7kh/PVHEgLtBlk1MJVZazMoOZoCBPUr/Uh8sDQ1UYACG6e4LGlfqkoHuw862bnm+YjDx0UQFp/eqCup/wlQvHvr9WdIzadsEMxI6sPRMb3YWNkYEJHiv8jzdLYrKwjpL+Z5HuP/KtYcM3OAWHPMLIinN5gfn6+/Adz6xlBFC8DNAAAAAElFTkSuQmCC&logoColor=white" />
  <img src="https://img.shields.io/badge/Python-3.9+-3776AB?style=for-the-badge&logo=python&logoColor=white" />
  <img src="https://img.shields.io/badge/Document_AI-4ECDC4?style=for-the-badge&logo=artificial-intelligence&logoColor=white" />
  <img src="https://img.shields.io/badge/Serverless-FFA116?style=for-the-badge&logo=aws-lambda&logoColor=white" />
  <img src="https://img.shields.io/badge/RAG-8B5CF6?style=for-the-badge&logo=openai&logoColor=white" />
</p>
<p align="center">
  <a href="https://docs.tensorlake.ai"><img src="https://img.shields.io/badge/docs-tensorlake.ai-blue?style=flat-square" /></a>
  <a href="https://pypi.org/project/tensorlake/"><img src="https://img.shields.io/pypi/v/tensorlake?style=flat-square&label=tensorlake" /></a>
  <a href="https://tlake.link/slack"><img src="https://img.shields.io/badge/slack-join_community-611f69.svg?style=flat-square&logo=slack" /></a>
  <img src="https://img.shields.io/badge/license-MIT-green?style=flat-square" />
</p>

## Transform Unstructured Data into Queryable and AI Ready Data on Snowflake

Tensorlake is a serverless platform for building data applications and agents in Python that can ingest and transform unstructured data before landing them in Snowflake's SQL database or Cortex Search Engine. This is an alternative to perform ETL orchestration with SQL expressions and UDF functions. 

Tensorlake's applications automatically behave like durable queues so you wouldn't need to setup Kafka or other queues to manage ingestion. The clusters automatically scales up as data is ingested to process them.

## Table of Contents
- [Example Use Cases](#use-cases)
  - [Document Ingestion Pipeline](#blueprint-document-ingestion-pipeline)
  - [Structured Data Extraction](#blueprint-structured-data-extraction) (*coming soon*)
  - [Document Indexing with Cortex](#blueprint-document-indexing-with-cortex) (*coming soon*)
- [Quick Overview: Tensorlake Applications](#quick-overview-tensorlake-applications)
- [Why This Integration Matters](#why-this-integration-matters)
- [Resources](#resources)

## Use Cases

We present some blueprints for production ready patterns to integrate with Snowflake and code that you can deploy under 2 minutes and expereince the integration.

### Blueprint: Document Ingestion Pipeline

![A diagram showing the pipeline for this Application](./sec-filings/Snowflake_SECFilings_Diagram.png)

The Tensoralake Application receives Document URLs over HTTP, uses an OCR API to parse the document, calls an LLM for structured extraction, and then uses Snowflake's JDBC driver to write structured data into your Snowflake Database. Once it's inside Snowflake you can do all sorts of analytics on the data. 

The Application is written in Python, without any external orchestration engines, so you can build and test it like any other normal application. You can use any OCR API in the Application, or even run open source OCR models on GPUs by annotating the OCR function with a GPU enabled hardware resource. 

Tensorlake automatically queues requests and scales out the cluster, there is no extra configuration required for handling spiky ingestion.

Try out the [code here](https://github.com/tensorlakeai/snowflake/tree/main/sec-filings).

### Blueprint: Structured Data Extraction

![Diagram of the Tensorlake Application that stores wikipedia pages in Snowflake for NLP querying with OpenAI.](./query-wikipedia/Snowflake_Wikipedia_Diagram.png)

The Tensorlake applications create an intelligent Wikipedia knowledge base through a two-stage pipeline. The first application (`extract-wikipedia`) accepts a page type (like "actors"), uses BeautifulSoup and Requests to crawl relevant Wikipedia pages, then leverages Tensorlake DocumentAI to parse HTML and extract structured information (birth dates, career highlights, key events) alongside textual summaries. Everything is stored in Snowflake with both structured data tables and text embeddings.

The second application (`query-wikipedia`) accepts natural language queries and orchestrates a sophisticated two-phase search. First, it queries the structured data using Snowflake Cortex, then uses those results as filters for semantic search through text embeddings. This hybrid approach - filtering by facts then searching by meaning - delivers highly relevant results. Finally, OpenAI GPT-4 generates contextual answers from the retrieved information.

The applications are written in pure Python with Tensorlake's automatic function orchestration - no Airflow, no Kafka, no complex infrastructure needed. The extraction application builds your knowledge base incrementally, while the query application provides instant answers. Each component handles its specialized task: BeautifulSoup for web scraping, Tensorlake for HTML parsing and information extraction, Snowflake for structured and vector storage with Cortex Search, and OpenAI for natural language generation.

Try out the [code here](./query-wikipedia).

## Quick Overview: Tensorlake Applications

For more complete documention on the Tensorlake Platform (including serverless Applications and Document AI), visit the [Tensorlake docs](https://docs.tensorlake.ai).

### Prerequisites

- Snowflake account
- Tensorlake API key ([get one here](https://cloud.tensorlake.ai))
- Python 3.9+

### Installation

Integrating Snowflake into a Tensorlake Application is easy. To get started, install the Tensorlake SDK:

```bash
# Install the Tensorlake SDK
pip install tensorlake
```

Then, store your Snowflake secrets on the Tensorlake platform:
```bash
# Set Tensorlake Secrets for deployed Applications
tensorlake secrets set SNOWFLAKE_ACCOUNT='YOUR_SNOWFLAKE_ACCOUNT'
tensorlake secrets set SNOWFLAKE_USER='YOUR_SNOWFLAKE_USER'
tensorlake secrets set SNOWFLAKE_PASSWORD='YOUR_SNOWFLAKE_PASSWORD'
tensorlake secrets set SNOWFLAKE_WAREHOUSE='YOUR_SNOWFLAKE_WAREHOUSE'
tensorlake secrets set SNOWFLAKE_DATABASE='YOUR_SNOWFLAKE_DATABASE'
tensorlake secrets set SNOWFLAKE_SCHEMA='YOUR_SNOWFLAKE_SCHEMA'
```

### Defining an image

Define an image to ensure your Application has access to the libraries it needs to complete the task.
```python
# Define the image for the application
image = (
    Image(base_image="python:3.11-slim", name="snowflake-sec")
    .run("pip install snowflake-connector-python pandas pyarrow")
)
```

### Entrypoint function
Your entrypoint function is defined by the `@application()` decorator. This decorator tells the Tensorlake platform which function starts the application. The entrypoint function name is also the name of the Application. For example, when deployed, this Application will be called `document_ingestion`:
```python
# Specify the entry point to the application
@application()
@function()
def document_ingestion(document_url:str) -> None:
    # Some code
```

### Image and secrets
Each function that is part of your Application needs to have a `function()` decorator. The `function()` decorator can accepts two parameters: `secrets` and `image`.

```python
# Specify any secrets needed for this funciton
# Specify the image needed for this funciton
@function(
  secrets=[
        "TENSORLAKE_API_KEY",
        "SNOWFLAKE_ACCOUNT",
        "SNOWFLAKE_USER", 
        "SNOWFLAKE_PASSWORD",
        "SNOWFLAKE_WAREHOUSE"
    ], 
    image=image
)
def write_to_snowflake(parse_id:str) -> None:
  # Some code
```

### Deploy your Application

Once you have written your application, you can deploy it with the Tensorlake `deploy` CLI command:

```bash
tensorlake deploy document-infestion.py
```

### Trigger your Application

Once deployed, you can trigger your application by posting to the HTTP endpoint. With Tensorlake's auto-scaling platform you can make 100,000s of requests and Tensorlake will automatically scale to handle them all, then automatically scale back. 

```bash
# Basic curl request to Tensorlake application endpoint
curl -X POST https://api.tensorlake.ai/applications/document-ingestion \
  -H "Authorization: Bearer YOUR_TENSORLAKE_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "url": "https://example.com/document.pdf"
  }'
```

## Why This Integration Matters

### Beyond Traditional ETL: Serverless Data Applications
Tensorlake is a complete serverless application platform that revolutionizes complex ETL:
- **Replace Complex ETL Stacks**: No more Airflow, Kafka, or queue management. Tensorlake applications automatically behave like durable queues with built-in orchestration
- **Python-Native Development**: Build data applications in pure Python instead of wrestling with SQL expressions and UDFs
- **Auto-Scaling Infrastructure**: Clusters automatically scale from 0 to thousands of workers as data flows increase
- **Direct Snowflake Integration**: Land processed data directly into Snowflake tables or Cortex Search without intermediate storage

### Intelligent Data Processing at Scale
As part of the Tensorlake platform, you also get comprehensive data processing, extraction, and ingestion out of the box:
- **Multi-Modal Data Handling**: Process documents, images, presentations, spreadsheets, and raw text in unified workflows
- **Adaptive Processing**: Dynamic model orchestration that adapts to data complexity in real-time
- **Layout-Aware Understanding**: Preserves document structure, tables, and semantic relationships
- **Guaranteed Processing**: Durable execution ensures every piece of data is processed without drops or failures

## Resources

- [Full API Documentation](https://docs.tensorlake.ai)
- [Snowflake Docs](https://docs.snowflake.com)

### Security and Compliance

- **SOC 2 Type II** certified infrastructure
- **HIPAA/GDPR** compliant processing
- **Row-level security** in Snowflake
- **Audit logging** for all operations

### Support

- **Tensorlake Slack**: [Join our community](https://tlake.link/slack)
- **GitHub Issues**: [Report bugs or request features](https://github.com/tensorlakeai/snowflake/issues)
- **Enterprise Support**: support@tensorlake.ai

---

<p align="center">
  <img src="https://img.shields.io/badge/Powered_by-Tensorlake-00A86B?style=flat-square&logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAABCGlDQ1BJQ0MgUHJvZmlsZQAAeJxjYGA8wQAELAYMDLl5JUVB7k4KEZFRCuwPGBiBEAwSk4sLGHADoKpv1yBqL+viUYcLcKakFicD6Q9ArFIEtBxopAiQLZIOYWuA2EkQtg2IXV5SUAJkB4DYRSFBzkB2CpCtkY7ETkJiJxcUgdT3ANk2uTmlyQh3M/Ck5oUGA2kOIJZhKGYIYnBncAL5H6IkfxEDg8VXBgbmCQixpJkMDNtbGRgkbiHEVBYwMPC3MDBsO48QQ4RJQWJRIliIBYiZ0tIYGD4tZ2DgjWRgEL7AwMAVDQsIHG5TALvNnSEfCNMZchhSgSKeDHkMyQx6QJYRgwGDIYMZAKbWPz9HbOBQAAAD20lEQVR42pWUb0zVZRTHv+c8v9+9V8CBIkzGDEOoBMw5NrfeeLWlsuWquV22XPXGTafp2krbkuWPuzSyrbZqOKj1zpFCazVcU2gDtnrVaIWKQyFlE0kEAsnLvfx+zzm94LL4Z6vvm+fZOd/n8/w5zw6wvBgxGDxKszleLkXLmltgAQDPFWcjkiwLpagQAISdocCaXvzw++QS77LAOcOO9UUUtscJulcZBZR2qRAADEPpu9B06kyq697txVBaDDNVhTEl06BGVwM665DZQVkBZQAEDnRc1R6Sy3eb50NngR4YcQjvXlctLl0gawFmwMp1JXzDVq8YAMJUIYS9xFQmQiAm0EzwsrTfPT/HoPREUbWumJV6lG1EWZmseU8RPo1L/amFz1IWogeTNTDmJNQKqSbF5c1ovTMAD2SQD0YvhB5f+RlCXAkCwWotLg3Von9cEIWDrSCUg5EHg+/vBxiY6uDiTIHhZ2HYJZ/yMfDga+SDCQCyqtbmPRTnBkKUCV+v6eU7WxCFgy5YALrkZ0Rh0IWAdhf8AsepQICEyswTaL834gDAtJhtyDA5IILxg6YgvdLzPEJtp+lFvgJAWecIoXO7xDvjabKeg8sfqWuyTZKiFmhxAMAkwz1Oht0vKSuOj/ZAQdHOKOI74oI4ZOEBuxDtiHLX9i4K73TPB9MY5zCz+uY3O1dlJoLo7M2IgPQUh7v3FUmerQ5N8yYrQsa1V1JTprlxy4Xbi71zDAKAo9defZENb/3xq7HT3fGLCa/Dc+4X9e93iU5l5EbWUMgAorB+gMRYctwIaoY2vPRFC1XbysbKjG3RjTVi8fMn5ee+JQA4duO1DW7Wiv4g4V8ncW5ayHonh54OhV0kR1JXZ9i/yAIo057M3EiFpgT+pO2BYlAcLolk8kY7ZUs/KP2yn2LNMdNS3WLfuXmgNbdk1Z4gqRARJP5MJKzV+rqihrf/KTThxOChM2zoSGZOJIMM4EZcjN6aaK0rbnjBU49JFUQE9YbeXBMy7i71bb5DPOmK0/bWY+8PHel7ZfMMpTZBBA6Fr559sunXU30nCpFpd1q1OStcM8ITftuxpz4eVVWiR3Wow937isKr3c8tgl2hVQ4UwMyED1JuCxJy4Gx50+C/ti9PPR7GsCnoy8qeDj88SSxHI7kh/PVHEgLtBlk1MJVZazMoOZoCBPUr/Uh8sDQ1UYACG6e4LGlfqkoHuw862bnm+YjDx0UQFp/eqCup/wlQvHvr9WdIzadsEMxI6sPRMb3YWNkYEJHiv8jzdLYrKwjpL+Z5HuP/KtYcM3OAWHPMLIinN5gfn6+/Adz6xlBFC8DNAAAAAElFTkSuQmCC)" />
</p>
